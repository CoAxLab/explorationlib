{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Test - setting _p target_ to less than one\n",
    "\n",
    "Unreliable rewards are behaving reliably in the code?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.6.7)\nHello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import explorationlib\n",
    "from explorationlib import agent\n",
    "from explorationlib import local_gym as gym\n",
    "\n",
    "from explorationlib.run import experiment\n",
    "from explorationlib.util import select_exp\n",
    "from explorationlib.util import load\n",
    "from explorationlib.util import save\n",
    "\n",
    "from explorationlib.plot import plot_position2d\n",
    "from explorationlib.plot import plot_length_hist\n",
    "from explorationlib.plot import plot_length\n",
    "from explorationlib.plot import plot_targets2d\n",
    "from explorationlib.plot import show_gif\n",
    "\n",
    "from explorationlib import score\n",
    "from explorationlib.score import search_efficiency\n",
    "from explorationlib.score import first_reward\n",
    "from explorationlib.score import average_reward\n",
    "from explorationlib.score import total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# Pretty plots\\n%matplotlib inline\\n%config InlineBackend.figure_format='retina'\\n%config IPCompleter.greedy=True\\n\\nplt.rcParams[\\\"axes.facecolor\\\"] = \\\"white\\\"\\nplt.rcParams[\\\"figure.facecolor\\\"] = \\\"white\\\"\\nplt.rcParams[\\\"font.size\\\"] = \\\"16\\\"\\n\\n# Uncomment for local development\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_formatted_code = \"# Pretty plots\\n%matplotlib inline\\n%config InlineBackend.figure_format='retina'\\n%config IPCompleter.greedy=True\\n\\nplt.rcParams[\\\"axes.facecolor\\\"] = \\\"white\\\"\\nplt.rcParams[\\\"figure.facecolor\\\"] = \\\"white\\\"\\nplt.rcParams[\\\"font.size\\\"] = \\\"16\\\"\\n\\n# Uncomment for local development\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Pretty plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"font.size\"] = \"16\"\n",
    "\n",
    "# Uncomment for local development\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# 1 targets, p_target = 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"# How long to run? Longer is better, but slower.\\nnum_steps = 100\\np_target = 1.0\\n\\nnum_experiments = 100\\ndetection_radius = 1\\nnum_targets = 3 # 5000-50000\\ntarget_boundary = (100, 100)\\n\\n# -\\nmin_length = 0.1\\nstep_size = 0.1\\n\\n# Create env \\nenv = gym.Field()\\ntargets = gym.uniform_targets(num_targets, target_boundary)\\nvalues = gym.constant_values(targets, 1.0)\\nenv.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\\n\\nind = 0\\nrewards =[]\\nfor _ in range(num_experiments):\\n    _, reward, _, _ = env.step(targets[ind])\\n    rewards.append(reward)\\n    env.reset()\\n\\nprint(np.mean(rewards))\";\n                var nbb_formatted_code = \"# How long to run? Longer is better, but slower.\\nnum_steps = 100\\np_target = 1.0\\n\\nnum_experiments = 100\\ndetection_radius = 1\\nnum_targets = 3  # 5000-50000\\ntarget_boundary = (100, 100)\\n\\n# -\\nmin_length = 0.1\\nstep_size = 0.1\\n\\n# Create env\\nenv = gym.Field()\\ntargets = gym.uniform_targets(num_targets, target_boundary)\\nvalues = gym.constant_values(targets, 1.0)\\nenv.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\\n\\nind = 0\\nrewards = []\\nfor _ in range(num_experiments):\\n    _, reward, _, _ = env.step(targets[ind])\\n    rewards.append(reward)\\n    env.reset()\\n\\nprint(np.mean(rewards))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "# How long to run? Longer is better, but slower.\n",
    "num_steps = 100\n",
    "p_target = 1.0\n",
    "\n",
    "num_experiments = 100\n",
    "detection_radius = 1\n",
    "num_targets = 3 # 5000-50000\n",
    "target_boundary = (100, 100)\n",
    "\n",
    "# -\n",
    "min_length = 0.1\n",
    "step_size = 0.1\n",
    "\n",
    "# Create env \n",
    "env = gym.Field()\n",
    "targets = gym.uniform_targets(num_targets, target_boundary)\n",
    "values = gym.constant_values(targets, 1.0)\n",
    "env.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\n",
    "\n",
    "ind = 0\n",
    "rewards =[]\n",
    "for _ in range(num_experiments):\n",
    "    _, reward, _, _ = env.step(targets[ind])\n",
    "    rewards.append(reward)\n",
    "    env.reset()\n",
    "\n",
    "print(np.mean(rewards))"
   ]
  },
  {
   "source": [
    "# 1 targets, p_target = 0.5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.49\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"# How long to run? Longer is better, but slower.\\nnum_steps = 100\\np_target = 0.5\\n\\nnum_experiments = 100\\ndetection_radius = 1\\nnum_targets = 3 # 5000-50000\\ntarget_boundary = (100, 100)\\n\\n# -\\nmin_length = 0.1\\nstep_size = 0.1\\n\\n# Create env \\nenv = gym.Field()\\ntargets = gym.uniform_targets(num_targets, target_boundary)\\nvalues = gym.constant_values(targets, 1.0)\\nenv.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\\n\\nind = 0\\nrewards =[]\\nfor _ in range(num_experiments):\\n    _, reward, _, _ = env.step(targets[ind])\\n    rewards.append(reward)\\n    env.reset()\\n\\nprint(np.mean(rewards))\";\n                var nbb_formatted_code = \"# How long to run? Longer is better, but slower.\\nnum_steps = 100\\np_target = 0.5\\n\\nnum_experiments = 100\\ndetection_radius = 1\\nnum_targets = 3  # 5000-50000\\ntarget_boundary = (100, 100)\\n\\n# -\\nmin_length = 0.1\\nstep_size = 0.1\\n\\n# Create env\\nenv = gym.Field()\\ntargets = gym.uniform_targets(num_targets, target_boundary)\\nvalues = gym.constant_values(targets, 1.0)\\nenv.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\\n\\nind = 0\\nrewards = []\\nfor _ in range(num_experiments):\\n    _, reward, _, _ = env.step(targets[ind])\\n    rewards.append(reward)\\n    env.reset()\\n\\nprint(np.mean(rewards))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "# How long to run? Longer is better, but slower.\n",
    "num_steps = 100\n",
    "p_target = 0.5\n",
    "\n",
    "num_experiments = 100\n",
    "detection_radius = 1\n",
    "num_targets = 3 # 5000-50000\n",
    "target_boundary = (100, 100)\n",
    "\n",
    "# -\n",
    "min_length = 0.1\n",
    "step_size = 0.1\n",
    "\n",
    "# Create env \n",
    "env = gym.Field()\n",
    "targets = gym.uniform_targets(num_targets, target_boundary)\n",
    "values = gym.constant_values(targets, 1.0)\n",
    "env.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\n",
    "\n",
    "ind = 0\n",
    "rewards =[]\n",
    "for _ in range(num_experiments):\n",
    "    _, reward, _, _ = env.step(targets[ind])\n",
    "    rewards.append(reward)\n",
    "    env.reset()\n",
    "\n",
    "print(np.mean(rewards))"
   ]
  },
  {
   "source": [
    "# 1 targets, p_target = 0.1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.09\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"# How long to run? Longer is better, but slower.\\nnum_steps = 100\\np_target = 0.1\\n\\nnum_experiments = 100\\ndetection_radius = 1\\nnum_targets = 3 # 5000-50000\\ntarget_boundary = (100, 100)\\n\\n# -\\nmin_length = 0.1\\nstep_size = 0.1\\n\\n# Create env \\nenv = gym.Field()\\ntargets = gym.uniform_targets(num_targets, target_boundary)\\nvalues = gym.constant_values(targets, 1.0)\\nenv.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\\n\\nind = 0\\nrewards =[]\\nfor _ in range(num_experiments):\\n    _, reward, _, _ = env.step(targets[ind])\\n    rewards.append(reward)\\n    env.reset()\\n\\nprint(np.mean(rewards))\";\n                var nbb_formatted_code = \"# How long to run? Longer is better, but slower.\\nnum_steps = 100\\np_target = 0.1\\n\\nnum_experiments = 100\\ndetection_radius = 1\\nnum_targets = 3  # 5000-50000\\ntarget_boundary = (100, 100)\\n\\n# -\\nmin_length = 0.1\\nstep_size = 0.1\\n\\n# Create env\\nenv = gym.Field()\\ntargets = gym.uniform_targets(num_targets, target_boundary)\\nvalues = gym.constant_values(targets, 1.0)\\nenv.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\\n\\nind = 0\\nrewards = []\\nfor _ in range(num_experiments):\\n    _, reward, _, _ = env.step(targets[ind])\\n    rewards.append(reward)\\n    env.reset()\\n\\nprint(np.mean(rewards))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {}
    }
   ],
   "source": [
    "# How long to run? Longer is better, but slower.\n",
    "num_steps = 100\n",
    "p_target = 0.1\n",
    "\n",
    "num_experiments = 100\n",
    "detection_radius = 1\n",
    "num_targets = 3 # 5000-50000\n",
    "target_boundary = (100, 100)\n",
    "\n",
    "# -\n",
    "min_length = 0.1\n",
    "step_size = 0.1\n",
    "\n",
    "# Create env \n",
    "env = gym.Field()\n",
    "targets = gym.uniform_targets(num_targets, target_boundary)\n",
    "values = gym.constant_values(targets, 1.0)\n",
    "env.add_targets(targets, values, detection_radius=detection_radius, p_target=p_target)\n",
    "\n",
    "ind = 0\n",
    "rewards =[]\n",
    "for _ in range(num_experiments):\n",
    "    _, reward, _, _ = env.step(targets[ind])\n",
    "    rewards.append(reward)\n",
    "    env.reset()\n",
    "\n",
    "print(np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}